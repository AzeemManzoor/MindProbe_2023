{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d409ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pehle men Images pr testing work krun ga sara "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d950b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from deepface import DeepFace\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('happy.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions =DeepFace.analyze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [{'emotion': {'angry': 19.328023493289948, 'disgust': 1.0912587866187096, 'fear': 26.14227831363678, 'happy': 45.231929421424866, 'sad': 7.125496119260788, 'surprise': 1.0591075755655766, 'neutral': 0.021909484348725528}, 'dominant_emotion': 'happy', 'region': {'x': 92, 'y': 47, 'w': 57, 'h': 57}, 'age': 16, 'gender': {'Woman': 99.43683743476868, 'Man': 0.5631594453006983}, 'dominant_gender': 'Woman', 'race': {'asian': 0.0014290642808693125, 'indian': 0.0004281452020758697, 'black': 5.314067369806907e-06, 'white': 99.40564032826664, 'middle eastern': 0.2395664251709834, 'latino hispanic': 0.35293379108213135}, 'dominant_race': 'white'}]\n",
    "\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ef75a",
   "metadata": {},
   "source": [
    "# Trying to make rectangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d72ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f329ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deec028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ooper tak saara kaam 1 image pr ho gya ha rectangle face k arround ban dya ha detection ho rhi ha image pr detection name b aa raha ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ab alag alag images pr further types of detection use kr ke check krunga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53662b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same kaam dosri image par kia ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('2.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17663b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same kaam teesri image pr kia ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4616ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('3.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same kaam 4th image pr kia ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('4.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same kaam 5th image pr kia ha results bilkul theek aa rhe hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e876dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('5.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa57602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# th image pr b result theek aya ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "246566bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[0;32m      4\u001b[0m predictions\u001b[38;5;241m=\u001b[39mDeepFace\u001b[38;5;241m.\u001b[39manalyze(img,actions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('6.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "predictions=DeepFace.analyze(img,actions=['emotion'])\n",
    "predictions\n",
    "# Convert the list of dictionaries to a single dictionary\n",
    "predictions = {k: v for d in predictions for k, v in d.items()}\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\n",
    "           predictions['dominant_emotion'],\n",
    "           (0,50),\n",
    "           font,1,\n",
    "           (0,0,255),\n",
    "           2,\n",
    "           cv2.LINE_4);\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb13bc5",
   "metadata": {},
   "source": [
    "#Real Time Face Emotion Detection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99797466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ab video pr kaam krunga img ki jga frames use kr k or baaki ki working b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf260c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.61it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.23it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.19it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.24it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.06it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.70it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.89it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.37it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Action: emotion: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 15\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Check if any face is detected\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Extract the first dictionary from the list\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\emotiondetection\\lib\\site-packages\\deepface\\DeepFace.py:313\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(img_path, actions, enforce_detection, detector_backend, align, silent)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[0;32m    311\u001b[0m resp_objects \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 313\u001b[0m img_objs \u001b[38;5;241m=\u001b[39m \u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_content, img_region, _ \u001b[38;5;129;01min\u001b[39;00m img_objs:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img_content\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m img_content\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\emotiondetection\\lib\\site-packages\\deepface\\commons\\functions.py:115\u001b[0m, in \u001b[0;36mextract_faces\u001b[1;34m(img, target_size, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace could not be detected. Please confirm that the picture is a face photo \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor consider to set enforce_detection param to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m [(img, img_region, \u001b[38;5;241m0\u001b[39m)]\n",
      "\u001b[1;31mValueError\u001b[0m: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    results = DeepFace.analyze(frame, actions=['emotion'])\n",
    "    \n",
    "    # Check if any face is detected\n",
    "    if len(results) > 0:\n",
    "        # Extract the first dictionary from the list\n",
    "        result = results[0]\n",
    "        dominant_emotion = result['dominant_emotion']\n",
    "    else:\n",
    "        dominant_emotion = \"No face detected\"\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, dominant_emotion, (0, 50), font, 1, (0, 0, 255), 2, cv2.LINE_4)\n",
    "    cv2.imshow(\"Original Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464384fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
